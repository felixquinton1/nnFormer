###############################################
I am running the following nnFormer: 3d_fullres
My trainer class is:  <class 'nnformer.training.network_training.nnFormerTrainerV2_nnformer_acdc.nnFormerTrainerV2_nnformer_acdc'>
For that I will be using the following configuration:
num_classes:  2
modalities:  {0: 'T1w'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'nonCT')])
stages...
stage:  0
{'batch_size': 4, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 14, 160, 160]), 'median_patient_size_in_voxels': array([102, 349, 448]), 'current_spacing': array([2.10004783, 0.9375    , 0.9375    ]), 'original_spacing': array([2.10004783, 0.9375    , 0.9375    ]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}
I am using stage 0 from these plans
I am using sample dice + CE loss
I am using data from this folder:  /home/felix/Bureau/db_nnFormer/nnFormer_preprocessed/Task001_ACDC/nnFormerData_plans_v2.1
###############################################
2022-07-21 10:03:14.293732: Using dummy2d data augmentation
[0.51612903 0.25806452 0.12903226 0.06451613 0.03225806]
loading dataset
loading all case properties
2022-07-21 10:03:14.338006: Creating new 5-fold cross-validation split...
2022-07-21 10:03:14.338776: Desired fold for training: 0
2022-07-21 10:03:14.338840: This split has 36 training and 9 validation cases.
unpacking dataset
/home/felix/anaconda3/envs/nnFormer2/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
done